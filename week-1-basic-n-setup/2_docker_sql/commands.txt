## DE Zoomcamp 1.2.1 I Introduction to Docker

### Random stuff

docker run hello-world 

docker run  -it ubuntu bash 

rm -rf /

docker run -it python:3.9 

docker run -it --entrypoint=bash python:3.9  
 -- inside bash of python container
 pip install pandas
    python
    import pandas as pd
    pd.__version__


### Buillding using Dockerfile 

docker build -t test:pandas .   # test is name of image, pandas is tag, . is current directory, -t is tag

docker run -it test:pandas 
( run script in contailer)
(build our first pipleine  with pipeline.py file)


### postgres on docker 

-- make docker compose file
mount a folder from host to postgres container 

-- postgres image
docker run -it \
-e POSTGRES_USER="root" \
-e POSTGRES_PASSWORD="root" \
-e POSTGRES_DB="ny_taxi" \
-v /e/DEZOOMCAMP/de-zc-2025/week-1-basic-n-setup/2_docker_sql/ny_taxi_postgres_data:/var/lib/postgresql/data \
-p 5432:5432 \
postgres:13

or 
(
docker run -it \
	-e POSTGRES_USER="root" \
	-e POSTGRES_PASSWORD="root" \
	-e POSTGRES_DB="ny_taxi" \
	-v $(pwd)/ny_taxi_postgres_data:/var/lib/postgresql/data \
	-p 5432:5432 postgres:13
)

go to new terminal window 
use pgcli to log into and interact with database 
pgcli \
	-h  localhost -p 5432 \
	-u root \
	-d ny_taxi
we are now connected to the database 

go to jupyter notebook and connect to the database


get data from csv file
$cp /e/DEZOOMCAMP/data/yellow_tripdata_2021-01/yellow_tripdata_2021-01.csv  .

--data description
https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf

sample data
$ head -n 100 yellow_tripdata_2021-01.csv  > yellow_head.csv

in jupyther connect to postgres using sqlalchemy
engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')


# pgadmin container 

docker run -it \
  -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
  -e PGADMIN_DEFAULT_PASSWORD="root" \
  -p 8080:80 \
  dpage/pgadmin4


put postgres and pgadmin in one network

$ docker network create pg-network  

run the postgres container again inside network 
docker run -it \
    -e POSTGRES_USER="root" \
    -e POSTGRES_PASSWORD="root" \
    -e POSTGRES_DB="ny_taxi" \
    -v /d/docker/dockerdesktopwsl/docker_mount/ny_taxi_postgres_data:/var/lib/postgresql/data \
    -p 5432:5432 \
    --network pg-network \
    --name pg-database \
    postgres:13


run the pgadmin container inside network 
docker run -it \
  -e PGADMIN_DEFAULT_EMAIL="admin@admin.com" \
  -e PGADMIN_DEFAULT_PASSWORD="root" \
  -p 8080:80 \
  --network pg-network \
  --name pg-pgadmin \
  dpage/pgadmin4




-- ## Dockerizing the Ingestion script

--1 creating script file 


  (optional convert jupyter nb to script)
  in bash 
  jupyter nbconvert --to script pipeline.ipynb

  (edit the script file as needed)

ingest_data.py script input arguments 

  URL="<https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2021-01.csv>"

python ingest_data.py \
  --user=root \
  --password=root \
  --host=localhost \
  --port=5432 \
  --db=ny_taxi \
  --table_name=yellow_taxi_trips \
  --url="${URL}"

--2 Dockerfile for the script

FROM python:3.9.1
RUN apt-get install wget
RUN pip install pandas sqlalchemy psycopg2
WORKDIR /app
COPY ingest_data.py ingest_data.py
ENTRYPOINT ["python", "ingest_data.py"]


--3 Build the image

docker build -t taxi_ingest:v001

--4 Run the image

( run the postgres container again inside network as localhost will not work because for container localhost is the container itself)   

(host data file locally with python http server and ipconfig to get the ip address)
python -m http.server
localhost:8000
IPv4 Address example: 172.24.208.1:8000
csv file url: http://

URL="http://
docker run -it \
  --network=pg-network \
  taxi_ingest:v001 \
  --user=root \
  --password=root \
  --host=pg-database \
  --port=5432 \
  --db=ny_taxi \
  --table_name=yellow_taxi_trips \
  --url="${URL}"


after configuring dockerfile 
build the image
run the container from the image


--## postgres and pgadmin in docker-compose 

